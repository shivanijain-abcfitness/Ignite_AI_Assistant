# ğŸ§  Ignite AI
- Ignite AI is a Spring Bootâ€“based chatbot that:
answers questions in real time using RAG (document ingestion â†’ embeddings â†’ semantic search),
securely automates membership actions (freeze/cancel) via existing eAPIs,
reduces support load while improving member satisfaction.

## ğŸš€ Features

- ğŸ–¼ï¸ Chat with Ignite AI , get answers to your questions
-    Freeze your membership at any time via Ignite AI instantly
-    Cancel your membership at any time via Ignite AI instantly
- ğŸ“„ Upload documents (PDF, TXT, etc.)
- ğŸ§© Extract and chunk document text
- ğŸ§  Generate embeddings via LM Studio
- ğŸ’¾ Store embeddings in Qdrant (vector database)
- ğŸ” Semantic search on query
- ğŸ’¬ Answer questions using retrieved chunks via LM Studio

---

## ğŸ› ï¸ Tech Stack

| Layer        | Technology                       |
|--------------|----------------------------------|
| Backend      | Spring Boot (WebFlux)            |
| Vector DB    | Qdrant (via Docker)              |
| Embeddings   | LM Studio `/v1/embeddings`       |
| LLM Chat     | LM Studio `/v1/chat/completions` |
| File Parsing | Apache Tika                      |
| Java Version | 17+                              |
| Build Tool   | Maven                            |

---
## âš™ï¸ Setup Instructions

### 1. ğŸ§¬ Prerequisites

- Java 17+
- Maven
- Docker
- [LM Studio](https://lmstudio.ai/) running locally with:
    - `/v1/embeddings` support
    - `/v1/chat/completions` support


### 2. ğŸ³ Qdrant Setup with Docker

```bash
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant

# Build the project
mvn clean install

# Run the app
mvn spring-boot:run
  ```` 

### 3. ğŸ–¥ï¸ Frontend Setup

```bash
# From the frontend directory (e.g., ./frontend)
npm install

# Run Project
npm start



